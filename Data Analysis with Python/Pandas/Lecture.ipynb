{"cells":[{"cell_type":"markdown","metadata":{"id":"F0w_M5qNNHqG"},"source":["![rmotr](https://user-images.githubusercontent.com/7065401/52071918-bda15380-2562-11e9-828c-7f95297e4a82.png)\n","<hr style=\"margin-bottom: 40px;\">\n","\n","<img src=\"https://user-images.githubusercontent.com/7065401/68501079-0695df00-023c-11ea-841f-455dac84a089.jpg\"\n","    style=\"width:400px; float: right; margin: 0 40px 40px 40px;\"></img>\n","\n","# Reading CSV and TXT files\n","\n","Rather than creating `Series` or `DataFrames` strutures from scratch, or even from Python core sequences or `ndarrays`, the most typical use of **pandas** is based on the loading of information from files or sources of information for further exploration, transformation and analysis.\n","\n","In this lecture we'll learn how to read comma-separated values files (.csv) and raw text files (.txt) into pandas `DataFrame`s."]},{"cell_type":"markdown","metadata":{"id":"oACG5aMoNHqJ"},"source":["![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n","\n","## Hands on! "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ITvA-nMWNHqK"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"LNL18NyXNHqM"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Reading data with Python\n","\n","As we saw on previous courses we can read data simply using Python.\n","\n","When you want to work with a file, the first thing to do is to open it. This is done by invoking the `open()` built-in function.\n","\n","`open()` has a single required argument that is the path to the file and has a single return, the file object.\n","\n","The `with` statement automatically takes care of closing the file once it leaves the `with` block, even in cases of error."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XEYUTWIpNHqM","outputId":"6593dacb-3e0d-417a-ba75-6c0b1fc83ae1"},"outputs":[{"name":"stdout","output_type":"stream","text":["<_io.TextIOWrapper name='btc-market-price.csv' mode='r' encoding='UTF-8'>\n"]}],"source":["filepath = 'btc-market-price.csv'\n","\n","with open(filepath, 'r') as reader:\n","    print(reader)"]},{"cell_type":"markdown","metadata":{"id":"fHq_CEE0NHqN"},"source":["Once the file is opened, we can read its content as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rc9IWiAfNHqO","outputId":"c2f7d705-ae5e-4201-a7a4-ae8d560295f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 2/4/17 0:00,1099.169125\n","\n","1 3/4/17 0:00,1141.813\n","\n","2 4/4/17 0:00,?\n","\n","3 5/4/17 0:00,1133.079314\n","\n","4 6/4/17 0:00,-\n","\n","5 7/4/17 0:00,-\n","\n","6 8/4/17 0:00,1181.149838\n","\n","7 9/4/17 0:00,1208.8005\n","\n","8 10/4/17 0:00,1207.744875\n","\n","9 11/4/17 0:00,1226.617038\n","\n"]}],"source":["filepath = 'btc-market-price.csv'\n","\n","with open(filepath, 'r') as reader:\n","    for index, line in enumerate(reader.readlines()):\n","        # read just the first 10 lines\n","        if (index < 10):\n","            print(index, line)"]},{"cell_type":"markdown","metadata":{"id":"DCUUelOENHqO"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Reading data with Pandas\n","\n","Probably one of the most recurrent types of work for data analysis: public data sources, logs, historical information tables, exports from databases. So the pandas library offers us functions to read and write files in multiple formats like CSV, JSON, XML and Excel's XLSX, all of them creating a `DataFrame` with the information read from the file.\n","\n","We'll learn how to read different type of data including:\n","- CSV files (.csv)\n","- Raw text files (.txt)\n","- JSON data from a file and from an API\n","- Data from a SQL query over a database\n","\n","There are many other available reading functions as the following table shows:\n","\n","![pandas read data table](https://user-images.githubusercontent.com/7065401/68400151-51d5c200-0156-11ea-9732-aa00400c8e4b.png)"]},{"cell_type":"markdown","metadata":{"id":"qwbt9tjeNHqP"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## The `read_csv` method\n","\n","The first method we'll learn is **read_csv**, that let us read comma-separated values (CSV) files and raw text (TXT) files into a `DataFrame`.\n","\n","The `read_csv` function is extremely powerful and you can specify a very broad set of parameters at import time that allow us to accurately configure how the data will be read and parsed by specifying the correct structure, enconding and other details. The most common parameters are as follows:\n","\n","- `filepath`: Path of the file to be read.\n","- `sep`: Character(s) that are used as a field separator in the file.\n","- `header`: Index of the row containing the names of the columns (None if none).\n","- `index_col`: Index of the column or sequence of indexes that should be used as index of rows of the data.\n","- `names`: Sequence containing the names of the columns (used together with header = None).\n","- `skiprows`: Number of rows or sequence of row indexes to ignore in the load.\n","- `na_values`: Sequence of values that, if found in the file, should be treated as NaN.\n","- `dtype`: Dictionary in which the keys will be column names and the values will be types of NumPy to which their content must be converted.\n","- `parse_dates`: Flag that indicates if Python should try to parse data with a format similar to dates as dates. You can enter a list of column names that must be joined for the parsing as a date.\n","- `date_parser`: Function to use to try to parse dates.\n","- `nrows`: Number of rows to read from the beginning of the file.\n","- `skip_footer`: Number of rows to ignore at the end of the file.\n","- `encoding`: Encoding to be expected from the file read.\n","- `squeeze`: Flag that indicates that if the data read only contains one column the result is a Series instead of a DataFrame.\n","- `thousands`: Character to use to detect the thousands separator.\n","- `decimal`: Character to use to detect the decimal separator.\n","- `skip_blank_lines`: Flag that indicates whether blank lines should be ignored.\n","\n","> Full `read_csv` documentation can be found here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html."]},{"cell_type":"markdown","metadata":{"id":"mK7jbBQNNHqR"},"source":["In this case we'll try to read our `btc-market-price.csv` CSV file using different parameters to parse it correctly.\n","\n","This file contains records of the mean price of Bitcoin per date."]},{"cell_type":"markdown","metadata":{"id":"ESt5OPvKNHqS"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Reading our first CSV file\n","\n","Everytime we call `read_csv` method, we'll need to pass an explicit `filepath` parameter indicating the path where our CSV file is.\n","\n","Any valid string path is acceptable. The string could be a URL. Valid URL schemes include HTTP, FTP, S3, and file. For file URLs, a host is expected. A local file could be: `file://localhost/path/to/table.csv`.\n","\n","For example we can use `read_csv` method to load data directly from an URL:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r1A93NDVNHqS","outputId":"840f3cea-9d25-4040-a3c7-cc958099d30a"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Country Name</th>\n","      <th>Country Code</th>\n","      <th>Year</th>\n","      <th>Value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Arab World</td>\n","      <td>ARB</td>\n","      <td>1968</td>\n","      <td>2.576068e+10</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Arab World</td>\n","      <td>ARB</td>\n","      <td>1969</td>\n","      <td>2.843420e+10</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Arab World</td>\n","      <td>ARB</td>\n","      <td>1970</td>\n","      <td>3.138550e+10</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Arab World</td>\n","      <td>ARB</td>\n","      <td>1971</td>\n","      <td>3.642691e+10</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Arab World</td>\n","      <td>ARB</td>\n","      <td>1972</td>\n","      <td>4.331606e+10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Country Name Country Code  Year         Value\n","0   Arab World          ARB  1968  2.576068e+10\n","1   Arab World          ARB  1969  2.843420e+10\n","2   Arab World          ARB  1970  3.138550e+10\n","3   Arab World          ARB  1971  3.642691e+10\n","4   Arab World          ARB  1972  4.331606e+10"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["csv_url = \"https://raw.githubusercontent.com/datasets/gdp/master/data/gdp.csv\"\n","\n","pd.read_csv(csv_url).head()"]},{"cell_type":"markdown","metadata":{"id":"9spH9AB5NHqT"},"source":["Or just use a local file:"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"TL7m3esDNHqT","outputId":"0e1fc13b-1ba1-4b28-a494-d6eebd80e3dc"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2/4/17 0:00</th>\n","      <th>1099.169125</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3/4/17 0:00</td>\n","      <td>1141.813</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4/4/17 0:00</td>\n","      <td>?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5/4/17 0:00</td>\n","      <td>1133.079314</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6/4/17 0:00</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7/4/17 0:00</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   2/4/17 0:00  1099.169125\n","0  3/4/17 0:00     1141.813\n","1  4/4/17 0:00            ?\n","2  5/4/17 0:00  1133.079314\n","3  6/4/17 0:00            -\n","4  7/4/17 0:00            -"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('btc-market-price.csv')\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"3XooNLqSNHqU"},"source":["In this case we let pandas infer everything related to our data, but in most of the cases we'll need to explicitly tell pandas how we want our data to be loaded. To do that we use parameters.\n","\n","Let's see how theses parameters work."]},{"cell_type":"markdown","metadata":{"id":"-dS1y6fGNHqU"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## First row behaviour with `header` parameter\n","\n","The CSV file we're reading has only two columns: `Timestamp` and `Price`. It doesn't have a header. Pandas automatically assigned the first row of data as headers, which is incorrect. We can overwrite this behavior with the `header` parameter."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5avxTUJ1NHqU"},"outputs":[],"source":["df = pd.read_csv('btc-market-price.csv',\n","                 header=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"40i86fuiNHqU","outputId":"4cd80c6f-7368-4a22-87f4-d6f385b54751"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2/4/17 0:00</td>\n","      <td>1099.169125</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3/4/17 0:00</td>\n","      <td>1141.813</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4/4/17 0:00</td>\n","      <td>?</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5/4/17 0:00</td>\n","      <td>1133.079314</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6/4/17 0:00</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             0            1\n","0  2/4/17 0:00  1099.169125\n","1  3/4/17 0:00     1141.813\n","2  4/4/17 0:00            ?\n","3  5/4/17 0:00  1133.079314\n","4  6/4/17 0:00            -"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"aTVZhdwVNHqU"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Missing values with `na_values` parameter\n","\n","We can define a `na_values` parameter with the values we want to be recognized as NA/NaN. In this case empty strings `''`, `?` and `-` will be recognized as null values."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zpefK1vcNHqV"},"outputs":[],"source":["df = pd.read_csv('btc-market-price.csv',\n","                 header=None,\n","                 na_values=['', '?', '-'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bSVNXi1-NHqV","outputId":"35726119-2420-4411-f208-ee2c90689af4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2/4/17 0:00</td>\n","      <td>1099.169125</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3/4/17 0:00</td>\n","      <td>1141.813000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4/4/17 0:00</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5/4/17 0:00</td>\n","      <td>1133.079314</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6/4/17 0:00</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             0            1\n","0  2/4/17 0:00  1099.169125\n","1  3/4/17 0:00  1141.813000\n","2  4/4/17 0:00          NaN\n","3  5/4/17 0:00  1133.079314\n","4  6/4/17 0:00          NaN"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"1NEqM-MCNHqV"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Column names using `names` parameter\n","\n","We'll add that columns names using the `names` parameter. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dk5rcN0INHqW"},"outputs":[],"source":["df = pd.read_csv('btc-market-price.csv',\n","                 header=None,\n","                 na_values=['', '?', '-'],\n","                 names=['Timestamp', 'Price'])"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"anPmWmjVNHqX","outputId":"fc512928-813d-4373-840b-c1354a719c87"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Timestamp</th>\n","      <th>Price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2/4/17 0:00</td>\n","      <td>1099.169125</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3/4/17 0:00</td>\n","      <td>1141.813000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4/4/17 0:00</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5/4/17 0:00</td>\n","      <td>1133.079314</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6/4/17 0:00</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Timestamp        Price\n","0  2/4/17 0:00  1099.169125\n","1  3/4/17 0:00  1141.813000\n","2  4/4/17 0:00          NaN\n","3  5/4/17 0:00  1133.079314\n","4  6/4/17 0:00          NaN"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"koT3pD1yNHqX"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Column types using `dtype` parameter\n","\n","\n","Without using the `dtype` parameter pandas will try to figure it out the type of each column automatically. We can use `dtype` parameter to force pandas to use certain dtype.\n","\n","In this case we'll force the `Price` column to be `float`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LelBa_W9NHqY"},"outputs":[],"source":["df = pd.read_csv('btc-market-price.csv',\n","                 header=None,\n","                 na_values=['', '?', '-'],\n","                 names=['Timestamp', 'Price'],\n","                 dtype={'Price': 'float'})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ecIUXC7-NHqY","outputId":"5ba1887c-1b7b-4326-cf89-4e84c8d9dbd9"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Timestamp</th>\n","      <th>Price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2/4/17 0:00</td>\n","      <td>1099.169125</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3/4/17 0:00</td>\n","      <td>1141.813000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4/4/17 0:00</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5/4/17 0:00</td>\n","      <td>1133.079314</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6/4/17 0:00</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Timestamp        Price\n","0  2/4/17 0:00  1099.169125\n","1  3/4/17 0:00  1141.813000\n","2  4/4/17 0:00          NaN\n","3  5/4/17 0:00  1133.079314\n","4  6/4/17 0:00          NaN"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QicCGmrgNHqY","outputId":"0b3551e0-08e0-48a3-8466-aad4d46a32ad"},"outputs":[{"data":{"text/plain":["Timestamp     object\n","Price        float64\n","dtype: object"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df.dtypes"]},{"cell_type":"markdown","metadata":{"id":"5cb1FtMZNHqZ"},"source":["The `Timestamp` column was interpreted as a regular string (`object` in pandas notation), we can parse it manually using a vectorized operation as we saw on previous courses.\n","\n","We'll parse `Timestamp` column to `Datetime` objects using `to_datetime` method:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yY7BNQukNHqZ","outputId":"f045e348-e615-4aa8-daa8-b49043814aff"},"outputs":[{"data":{"text/plain":["0   2017-02-04\n","1   2017-03-04\n","2   2017-04-04\n","3   2017-05-04\n","4   2017-06-04\n","Name: Timestamp, dtype: datetime64[ns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["pd.to_datetime(df['Timestamp']).head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y33JAJ6lNHqZ"},"outputs":[],"source":["df['Timestamp'] = pd.to_datetime(df['Timestamp'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"48u8D67cNHqZ","outputId":"2ed5605f-a718-4412-955d-5b498a178943"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Timestamp</th>\n","      <th>Price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-02-04</td>\n","      <td>1099.169125</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-03-04</td>\n","      <td>1141.813000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-04-04</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2017-05-04</td>\n","      <td>1133.079314</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2017-06-04</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Timestamp        Price\n","0 2017-02-04  1099.169125\n","1 2017-03-04  1141.813000\n","2 2017-04-04          NaN\n","3 2017-05-04  1133.079314\n","4 2017-06-04          NaN"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A576BoWqNHqa","outputId":"e63c688b-bb63-4412-ab70-c3da74abefc9"},"outputs":[{"data":{"text/plain":["Timestamp    datetime64[ns]\n","Price               float64\n","dtype: object"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["df.dtypes"]},{"cell_type":"markdown","metadata":{"id":"K9dq04gwNHqa"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Date parser using `parse_dates` parameter\n","\n","Another way of dealing with `Datetime` objects is using `parse_dates` parameter with the position of the columns with dates."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"3_LECbafNHqb"},"outputs":[],"source":["df = pd.read_csv('btc-market-price.csv',\n","                 header=None,\n","                 na_values=['', '?', '-'],\n","                 names=['Timestamp', 'Price'],\n","                 dtype={'Price': 'float'},\n","                 parse_dates=[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"om7SRRVeNHqb","outputId":"465d5b27-57c6-458b-9434-d846113e0122"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Timestamp</th>\n","      <th>Price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-02-04</td>\n","      <td>1099.169125</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-03-04</td>\n","      <td>1141.813000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-04-04</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2017-05-04</td>\n","      <td>1133.079314</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2017-06-04</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Timestamp        Price\n","0 2017-02-04  1099.169125\n","1 2017-03-04  1141.813000\n","2 2017-04-04          NaN\n","3 2017-05-04  1133.079314\n","4 2017-06-04          NaN"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bG5y-FYcNHqb","outputId":"505b070e-3a43-4c63-94d8-f1d9516620f7"},"outputs":[{"data":{"text/plain":["Timestamp    datetime64[ns]\n","Price               float64\n","dtype: object"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["df.dtypes"]},{"cell_type":"markdown","metadata":{"id":"gUk8zmokNHqc"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Adding index to our data using `index_col` parameter\n","\n","By default, pandas will automatically assign a numeric autoincremental index or row label starting with zero. You may want to leave the default index as such if your data doesn’t have a column with unique values that can serve as a better index. In case there is a column that you feel would serve as a better index, you can override the default behavior by setting `index_col` property to a column. It takes a numeric value representing the index or a string of the column name for setting a single column as index or a list of numeric values or strings for creating a multi-index.\n","\n","In our data, we are choosing the first column, `Timestamp`, as index (index=0) by passing zero to the `index_col` argument."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EOAtIYkgNHqc"},"outputs":[],"source":["df = pd.read_csv('btc-market-price.csv',\n","                 header=None,\n","                 na_values=['', '?', '-'],\n","                 names=['Timestamp', 'Price'],\n","                 dtype={'Price': 'float'},\n","                 parse_dates=[0],\n","                 index_col=[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5bQ3KcnANHqc","outputId":"7dcbb297-95c5-44fa-e476-cba529a1cf65"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Price</th>\n","    </tr>\n","    <tr>\n","      <th>Timestamp</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2017-02-04</th>\n","      <td>1099.169125</td>\n","    </tr>\n","    <tr>\n","      <th>2017-03-04</th>\n","      <td>1141.813000</td>\n","    </tr>\n","    <tr>\n","      <th>2017-04-04</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2017-05-04</th>\n","      <td>1133.079314</td>\n","    </tr>\n","    <tr>\n","      <th>2017-06-04</th>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  Price\n","Timestamp              \n","2017-02-04  1099.169125\n","2017-03-04  1141.813000\n","2017-04-04          NaN\n","2017-05-04  1133.079314\n","2017-06-04          NaN"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_eEXhPRNHqc","outputId":"3c289879-569d-4960-eea1-eb9272132ed3"},"outputs":[{"data":{"text/plain":["Price    float64\n","dtype: object"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["df.dtypes"]},{"cell_type":"markdown","metadata":{"id":"Kh3v_FHHNHqc"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## A more challenging parsing\n","\n","Now we'll read another CSV file. This file has the following columns:\n","\n","- `first_name`\n","- `last_name`\n","- `age`\n","- `math_score`\n","- `french_score`\n","- `next_test_date`\n","\n","Let's read it and see how it looks like."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ZyGQt38NHqc"},"outputs":[],"source":["exam_df = pd.read_csv('exam_review.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"7D_EHhYYNHqd","outputId":"c32e30d8-c59e-4a9b-bdda-0220fb09fe0a"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>first_name&gt;last_name&gt;age&gt;math_score&gt;french_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Ray&gt;Morley&gt;18&gt;\"68</th>\n","      <th>000\"&gt;\"75</th>\n","      <td>000\"</td>\n","    </tr>\n","    <tr>\n","      <th>Melvin&gt;Scott&gt;24&gt;77&gt;83</th>\n","      <th>NaN</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>Amirah&gt;Haley&gt;22&gt;92&gt;67</th>\n","      <th>NaN</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>Gerard&gt;Mills&gt;19&gt;\"78</th>\n","      <th>000\"&gt;72</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>Amy&gt;Grimes&gt;23&gt;91&gt;81</th>\n","      <th>NaN</th>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               first_name>last_name>age>math_score>french_score\n","Ray>Morley>18>\"68     000\">\"75                                             000\"\n","Melvin>Scott>24>77>83 NaN                                                   NaN\n","Amirah>Haley>22>92>67 NaN                                                   NaN\n","Gerard>Mills>19>\"78   000\">72                                               NaN\n","Amy>Grimes>23>91>81   NaN                                                   NaN"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["exam_df"]},{"cell_type":"markdown","metadata":{"id":"nUyUqswhNHqd"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Custom data delimiters using `sep` parameter\n","\n","We can define which delimiter to use by using the `sep` parameter. If we don't use the `sep` parameter, pandas will automatically detect the separator.\n","\n","In most of the CSV files separator will be comma (`,`) and will be automatically detected. But we can find files with other separators like semicolon (`;`), tabs (`\\t`, specially on TSV files), whitespaces or any other special character.\n","\n","In this case the separator is a `>` character."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VUKM1Bd1NHqd"},"outputs":[],"source":["exam_df = pd.read_csv('exam_review.csv',\n","                      sep='>')"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"83aS94mRNHqe","outputId":"edbb1f0b-5c20-41d9-f59b-020a564564c7"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","      <th>math_score</th>\n","      <th>french_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ray</td>\n","      <td>Morley</td>\n","      <td>18</td>\n","      <td>68,000</td>\n","      <td>75,000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Melvin</td>\n","      <td>Scott</td>\n","      <td>24</td>\n","      <td>77</td>\n","      <td>83</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Amirah</td>\n","      <td>Haley</td>\n","      <td>22</td>\n","      <td>92</td>\n","      <td>67</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Gerard</td>\n","      <td>Mills</td>\n","      <td>19</td>\n","      <td>78,000</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Amy</td>\n","      <td>Grimes</td>\n","      <td>23</td>\n","      <td>91</td>\n","      <td>81</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name  age math_score french_score\n","0        Ray    Morley   18     68,000       75,000\n","1     Melvin     Scott   24         77           83\n","2     Amirah     Haley   22         92           67\n","3     Gerard     Mills   19     78,000           72\n","4        Amy    Grimes   23         91           81"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["exam_df"]},{"cell_type":"markdown","metadata":{"id":"OB0oiEelNHqe"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Custom data encoding\n","\n","Files are stored using different \"encodings\". You've probably heard about ASCII, UTF-8, latin1, etc.\n","\n","While reading data custom encoding can be defined with the `encoding` parameter.\n","\n","- `encoding='UTF-8'`: will be used if data is UTF-8 encoded.\n","- `encoding='iso-8859-1'`: will be used if data is ISO/IEC 8859-1 (\"extended ASCII\") encoded.\n","\n","In our case we don't need a custom enconding as data is properly loaded."]},{"cell_type":"markdown","metadata":{"id":"tevyWDCUNHqe"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Custom numeric `decimal` and `thousands` character  \n","\n","The decimal and thousands characters could change between datasets. If we have a column containing a comma (`,`) to indicate the decimal or thousands place, then this column would be considered a string and not numeric."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PB5Rn_t3NHqe"},"outputs":[],"source":["exam_df = pd.read_csv('exam_review.csv',\n","                      sep='>')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LwsaUh1BNHqf","outputId":"dc09a796-357d-450e-a786-e4bf6e2e3988"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","      <th>math_score</th>\n","      <th>french_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ray</td>\n","      <td>Morley</td>\n","      <td>18</td>\n","      <td>68,000</td>\n","      <td>75,000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Melvin</td>\n","      <td>Scott</td>\n","      <td>24</td>\n","      <td>77</td>\n","      <td>83</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Amirah</td>\n","      <td>Haley</td>\n","      <td>22</td>\n","      <td>92</td>\n","      <td>67</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Gerard</td>\n","      <td>Mills</td>\n","      <td>19</td>\n","      <td>78,000</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Amy</td>\n","      <td>Grimes</td>\n","      <td>23</td>\n","      <td>91</td>\n","      <td>81</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name  age math_score french_score\n","0        Ray    Morley   18     68,000       75,000\n","1     Melvin     Scott   24         77           83\n","2     Amirah     Haley   22         92           67\n","3     Gerard     Mills   19     78,000           72\n","4        Amy    Grimes   23         91           81"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["exam_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQQ3y92LNHqf","outputId":"619bac0a-9662-4ad4-e046-70078a391aef"},"outputs":[{"data":{"text/plain":["math_score      object\n","french_score    object\n","dtype: object"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["exam_df[['math_score', 'french_score']].dtypes"]},{"cell_type":"markdown","metadata":{"id":"6oKP3_KYNHqg"},"source":["To solve that, ensuring such columns are interpreted as integer values, we'll need to use the `decimal` and/or `thousands` parameters to indicate correct decimal and/or thousands indicators."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q2Xeu6-aNHqg"},"outputs":[],"source":["exam_df = pd.read_csv('exam_review.csv',\n","                      sep='>',\n","                      decimal=',')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KCyJmZJRNHqh","outputId":"eb93b493-8d33-416d-986d-0ae508e43089"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","      <th>math_score</th>\n","      <th>french_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ray</td>\n","      <td>Morley</td>\n","      <td>18</td>\n","      <td>68.0</td>\n","      <td>75.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Melvin</td>\n","      <td>Scott</td>\n","      <td>24</td>\n","      <td>77.0</td>\n","      <td>83.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Amirah</td>\n","      <td>Haley</td>\n","      <td>22</td>\n","      <td>92.0</td>\n","      <td>67.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Gerard</td>\n","      <td>Mills</td>\n","      <td>19</td>\n","      <td>78.0</td>\n","      <td>72.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Amy</td>\n","      <td>Grimes</td>\n","      <td>23</td>\n","      <td>91.0</td>\n","      <td>81.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name  age  math_score  french_score\n","0        Ray    Morley   18        68.0          75.0\n","1     Melvin     Scott   24        77.0          83.0\n","2     Amirah     Haley   22        92.0          67.0\n","3     Gerard     Mills   19        78.0          72.0\n","4        Amy    Grimes   23        91.0          81.0"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["exam_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IceQhjjSNHqh","outputId":"ed780e01-8a6b-4f48-ec10-87a3ef92237a"},"outputs":[{"data":{"text/plain":["math_score      float64\n","french_score    float64\n","dtype: object"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["exam_df[['math_score', 'french_score']].dtypes"]},{"cell_type":"markdown","metadata":{"id":"xXXOpO8eNHqh"},"source":["Let's see what happens with the `thousands` parameter:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H3PUUMmxNHqh","outputId":"fe5ba473-90c9-4bdc-a8b4-ff6ad98a2033"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","      <th>math_score</th>\n","      <th>french_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ray</td>\n","      <td>Morley</td>\n","      <td>18</td>\n","      <td>68000</td>\n","      <td>75000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Melvin</td>\n","      <td>Scott</td>\n","      <td>24</td>\n","      <td>77</td>\n","      <td>83</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Amirah</td>\n","      <td>Haley</td>\n","      <td>22</td>\n","      <td>92</td>\n","      <td>67</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Gerard</td>\n","      <td>Mills</td>\n","      <td>19</td>\n","      <td>78000</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Amy</td>\n","      <td>Grimes</td>\n","      <td>23</td>\n","      <td>91</td>\n","      <td>81</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name  age  math_score  french_score\n","0        Ray    Morley   18       68000         75000\n","1     Melvin     Scott   24          77            83\n","2     Amirah     Haley   22          92            67\n","3     Gerard     Mills   19       78000            72\n","4        Amy    Grimes   23          91            81"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["pd.read_csv('exam_review.csv',\n","            sep='>',\n","            thousands=',')"]},{"cell_type":"markdown","metadata":{"id":"FzJLK2gQNHqi"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Excluding specific rows\n","\n","We can use the `skiprows` to:\n","\n","- Exclude reading specified number of rows from the beginning of a file, by passing an integer argument. **This removes the header too**.\n","- Skip reading specific row indices from a file, by passing a list containing row indices to skip."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HkrliCEENHqi"},"outputs":[],"source":["exam_df = pd.read_csv('exam_review.csv',\n","                      sep='>',\n","                      decimal=',')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GF7cuwdaNHqi","outputId":"e17f528c-c32e-4033-90fb-402f32629254"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","      <th>math_score</th>\n","      <th>french_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ray</td>\n","      <td>Morley</td>\n","      <td>18</td>\n","      <td>68.0</td>\n","      <td>75.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Melvin</td>\n","      <td>Scott</td>\n","      <td>24</td>\n","      <td>77.0</td>\n","      <td>83.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Amirah</td>\n","      <td>Haley</td>\n","      <td>22</td>\n","      <td>92.0</td>\n","      <td>67.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Gerard</td>\n","      <td>Mills</td>\n","      <td>19</td>\n","      <td>78.0</td>\n","      <td>72.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Amy</td>\n","      <td>Grimes</td>\n","      <td>23</td>\n","      <td>91.0</td>\n","      <td>81.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name  age  math_score  french_score\n","0        Ray    Morley   18        68.0          75.0\n","1     Melvin     Scott   24        77.0          83.0\n","2     Amirah     Haley   22        92.0          67.0\n","3     Gerard     Mills   19        78.0          72.0\n","4        Amy    Grimes   23        91.0          81.0"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["exam_df"]},{"cell_type":"markdown","metadata":{"id":"11SagrpgNHqi"},"source":["To skip reading the first 2 rows from this file, we can use `skiprows=2`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7AT7QxikNHqj","outputId":"0e4cab99-b75e-4720-df05-a87021ef8476"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Melvin</th>\n","      <th>Scott</th>\n","      <th>24</th>\n","      <th>77</th>\n","      <th>83</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Amirah</td>\n","      <td>Haley</td>\n","      <td>22</td>\n","      <td>92</td>\n","      <td>67</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Gerard</td>\n","      <td>Mills</td>\n","      <td>19</td>\n","      <td>78,000</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Amy</td>\n","      <td>Grimes</td>\n","      <td>23</td>\n","      <td>91</td>\n","      <td>81</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Melvin   Scott  24      77  83\n","0  Amirah   Haley  22      92  67\n","1  Gerard   Mills  19  78,000  72\n","2     Amy  Grimes  23      91  81"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["pd.read_csv('exam_review.csv',\n","            sep='>',\n","            skiprows=2)"]},{"cell_type":"markdown","metadata":{"id":"tojIBKI2NHqj"},"source":["As the header is considered as the first row, to skip reading data rows 1 and 3, we can use `skiprows=[1,3]`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NokodYkBNHqj"},"outputs":[],"source":["exam_df = pd.read_csv('exam_review.csv',\n","                      sep='>',\n","                      decimal=',',\n","                      skiprows=[1,3])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ckhZk8LENHqk","outputId":"423d5865-a93a-44d1-985c-f25733c136ce"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","      <th>math_score</th>\n","      <th>french_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Melvin</td>\n","      <td>Scott</td>\n","      <td>24</td>\n","      <td>77.0</td>\n","      <td>83</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Gerard</td>\n","      <td>Mills</td>\n","      <td>19</td>\n","      <td>78.0</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Amy</td>\n","      <td>Grimes</td>\n","      <td>23</td>\n","      <td>91.0</td>\n","      <td>81</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name  age  math_score  french_score\n","0     Melvin     Scott   24        77.0            83\n","1     Gerard     Mills   19        78.0            72\n","2        Amy    Grimes   23        91.0            81"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["exam_df"]},{"cell_type":"markdown","metadata":{"id":"jZJAhY9nNHqk"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Get rid of blank lines\n","\n","The `skip_blank_lines` parameter is set to `True` so blank lines are skipped while we read files.\n","\n","If we set this parameter to `False`, then every blank line will be loaded with `NaN` values into the `DataFrame`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7BlerYdpNHqk","outputId":"741e2990-8806-493a-f99d-53f900d68cd5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","      <th>math_score</th>\n","      <th>french_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ray</td>\n","      <td>Morley</td>\n","      <td>18.0</td>\n","      <td>68,000</td>\n","      <td>75,000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Melvin</td>\n","      <td>Scott</td>\n","      <td>24.0</td>\n","      <td>77</td>\n","      <td>83</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Amirah</td>\n","      <td>Haley</td>\n","      <td>22.0</td>\n","      <td>92</td>\n","      <td>67</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Gerard</td>\n","      <td>Mills</td>\n","      <td>19.0</td>\n","      <td>78,000</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Amy</td>\n","      <td>Grimes</td>\n","      <td>23.0</td>\n","      <td>91</td>\n","      <td>81</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name   age math_score french_score\n","0        Ray    Morley  18.0     68,000       75,000\n","1     Melvin     Scott  24.0         77           83\n","2     Amirah     Haley  22.0         92           67\n","3        NaN       NaN   NaN        NaN          NaN\n","4     Gerard     Mills  19.0     78,000           72\n","5        Amy    Grimes  23.0         91           81"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["pd.read_csv('exam_review.csv',\n","            sep='>',\n","            skip_blank_lines=False)"]},{"cell_type":"markdown","metadata":{"id":"fCaZWVF3NHql"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Loading specific columns\n","\n","We can use the `usecols` parameter when we want to load just specific columns and not all of them.\n","\n","Performance wise, it is better because instead of loading an entire dataframe into memory and then deleting the not required columns, we can select the columns that we’ll need, while loading the dataset itself.\n","\n","As a parameter to `usecols`, you can pass either a list of strings corresponding to the column names or a list of integers corresponding to column index."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yup-rb7wNHql","outputId":"ecc4e7b0-b474-4511-973d-83e892185808"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ray</td>\n","      <td>Morley</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Melvin</td>\n","      <td>Scott</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Amirah</td>\n","      <td>Haley</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Gerard</td>\n","      <td>Mills</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Amy</td>\n","      <td>Grimes</td>\n","      <td>23</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name  age\n","0        Ray    Morley   18\n","1     Melvin     Scott   24\n","2     Amirah     Haley   22\n","3     Gerard     Mills   19\n","4        Amy    Grimes   23"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["pd.read_csv('exam_review.csv',\n","            usecols=['first_name', 'last_name', 'age'],\n","            sep='>')"]},{"cell_type":"markdown","metadata":{"id":"RpWKy8zcNHql"},"source":["Or using just the column position:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cC06WrF6NHql","outputId":"239187c8-7956-4931-fa59-8ea41349bb86"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ray</td>\n","      <td>Morley</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Melvin</td>\n","      <td>Scott</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Amirah</td>\n","      <td>Haley</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Gerard</td>\n","      <td>Mills</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Amy</td>\n","      <td>Grimes</td>\n","      <td>23</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name  age\n","0        Ray    Morley   18\n","1     Melvin     Scott   24\n","2     Amirah     Haley   22\n","3     Gerard     Mills   19\n","4        Amy    Grimes   23"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["pd.read_csv('exam_review.csv',\n","            usecols=[0, 1, 2],\n","            sep='>')"]},{"cell_type":"markdown","metadata":{"id":"1yRFnCAWNHqm"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Using a `Series` instead of `DataFrame`\n","\n","If the parsed data only contains one column then we can return a Series by setting the `squeeze` parameter to `True`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1FxT-mcNHqm"},"outputs":[],"source":["exam_test_1 = pd.read_csv('exam_review.csv',\n","                          sep='>',\n","                          usecols=['last_name'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fbO4mRcVNHqm","outputId":"6dfaa5ad-b684-47de-a584-f191695ca44f"},"outputs":[{"data":{"text/plain":["pandas.core.frame.DataFrame"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["type(exam_test_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJENkKOBNHqn"},"outputs":[],"source":["exam_test_2 = pd.read_csv('exam_review.csv',\n","                          sep='>',\n","                          usecols=['last_name'],\n","                          squeeze=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qboU9jAINHqn","outputId":"f530993e-5bb3-4512-9623-fec31d83b596"},"outputs":[{"data":{"text/plain":["pandas.core.series.Series"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["type(exam_test_2)"]},{"cell_type":"markdown","metadata":{"id":"Aol_EQk1NHqn"},"source":["![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n","\n","## Save to CSV file\n","\n","Finally we can also save our `DataFrame` as a CSV file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pnmx591NNHqn","outputId":"ff7d7139-3680-4f4f-d91d-062f8ef24d79"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","      <th>math_score</th>\n","      <th>french_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Melvin</td>\n","      <td>Scott</td>\n","      <td>24</td>\n","      <td>77.0</td>\n","      <td>83</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Gerard</td>\n","      <td>Mills</td>\n","      <td>19</td>\n","      <td>78.0</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Amy</td>\n","      <td>Grimes</td>\n","      <td>23</td>\n","      <td>91.0</td>\n","      <td>81</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name  age  math_score  french_score\n","0     Melvin     Scott   24        77.0            83\n","1     Gerard     Mills   19        78.0            72\n","2        Amy    Grimes   23        91.0            81"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["exam_df"]},{"cell_type":"markdown","metadata":{"id":"yGNSsq6LNHqo"},"source":["We can simply generate a CSV string from our `DataFrame`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9qeIjmGDNHqo","outputId":"b9abe194-0c72-4b1e-ea5d-542f6266857b"},"outputs":[{"data":{"text/plain":["',first_name,last_name,age,math_score,french_score\\n0,Melvin,Scott,24,77.0,83\\n1,Gerard,Mills,19,78.0,72\\n2,Amy,Grimes,23,91.0,81\\n'"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["exam_df.to_csv()"]},{"cell_type":"markdown","metadata":{"id":"8cV2IZnRNHqo"},"source":["Or specify a file path where we want our generated CSV code to be saved:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBXx84DsNHqp"},"outputs":[],"source":["exam_df.to_csv('out.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xpBQwj0UNHqp","outputId":"c49d0b4b-8948-4fbf-f25e-048a94329152"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","      <th>math_score</th>\n","      <th>french_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Melvin</td>\n","      <td>Scott</td>\n","      <td>24</td>\n","      <td>77.0</td>\n","      <td>83</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Gerard</td>\n","      <td>Mills</td>\n","      <td>19</td>\n","      <td>78.0</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Amy</td>\n","      <td>Grimes</td>\n","      <td>23</td>\n","      <td>91.0</td>\n","      <td>81</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0 first_name last_name  age  math_score  french_score\n","0           0     Melvin     Scott   24        77.0            83\n","1           1     Gerard     Mills   19        78.0            72\n","2           2        Amy    Grimes   23        91.0            81"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["pd.read_csv('out.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L0AOc-i_NHqq"},"outputs":[],"source":["exam_df.to_csv('out.csv',\n","               index=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"-iJpJkbbNHqq","outputId":"ff4b4590-34d4-4e73-a2bf-8fea932f6b48"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","      <th>math_score</th>\n","      <th>french_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Melvin</td>\n","      <td>Scott</td>\n","      <td>24</td>\n","      <td>77.0</td>\n","      <td>83</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Gerard</td>\n","      <td>Mills</td>\n","      <td>19</td>\n","      <td>78.0</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Amy</td>\n","      <td>Grimes</td>\n","      <td>23</td>\n","      <td>91.0</td>\n","      <td>81</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name  age  math_score  french_score\n","0     Melvin     Scott   24        77.0            83\n","1     Gerard     Mills   19        78.0            72\n","2        Amy    Grimes   23        91.0            81"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["pd.read_csv('out.csv')"]},{"cell_type":"markdown","metadata":{"id":"jjmrxcO1NHqq"},"source":["![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"provenance":[{"file_id":"https://github.com/ine-rmotr-curriculum/RDP-Reading-Data-with-Python-and-Pandas/blob/master/unit-1-reading-data-with-python-and-pandas/lesson-1-reading-csv-and-txt-files/files/Lecture.ipynb","timestamp":1684258396299}]}},"nbformat":4,"nbformat_minor":0}